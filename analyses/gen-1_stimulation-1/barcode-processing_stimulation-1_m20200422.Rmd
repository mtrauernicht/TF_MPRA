---
title: "Barcode processing - pMT02 - stimulation 1"
author: "Max Trauernicht"
date: "`r format(Sys.time(), '%Y-%m-%d')`"
output: 
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
  #   toc: true
  #   toc_float: true
  #   code_folding: show
  # editor_options:
  #   chunk_output_type: console
---

*knitr document van Steensel lab*

# TF reporter barcode processing - pMT02 - stimulation 1

## Introduction
18,000 TF reporters on pMT02 were transfected into mESCs and NPCs (in total 7 different conditions), sequencing data yielded barcode counts of these experiments. These counts will be processed in this script. 


```{r setup, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
StartTime <-Sys.time()

# 8-digit Date tag:
Date <- substr(gsub("-","",Sys.time()),1,8) 
# libraries:
library(data.table)
library(plyr)
library(stringr)
library(ggpubr)
library(GGally)
library(vwr)
library(dplyr)
library(tibble)
library(plotly)
library(ggbeeswarm)
library(haven)
library(readr)
library(parallel)
library(RColorBrewer)
library(gridExtra)
library(LncFinder)
library(tidyr)
library(DESeq2)
library(PCAtools)
library(pheatmap)
```


```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Custom functions
SetFileName <- function(filename, initials) {
  # Set filename with extension and initials to make filename with date integrated.
  filename <- substitute(filename)
  initials <- substitute(initials)
  filename <- paste0(initials, Date, filename)
  filename
}

ReadFasta<-function(file) {
   # Read the file line by line
   fasta<-readLines(file)
   # Identify header lines
   ind<-grep(">", fasta)
   # Identify the sequence lines
   s<-data.frame(ind=ind, from=ind+1, to=c((ind-1)[-1], length(fasta)))
   # Process sequence lines
   seqs<-rep(NA, length(ind))
   for(i in 1:length(ind)) {
      seqs[i]<-paste(fasta[s$from[i]:s$to[i]], collapse="")
   }
   # Create a data frame 
   DF<-data.frame(name=gsub(">", "", fasta[ind]), sequence=seqs)
   # Return the data frame as a result object from the function
   return(DF)
}

# From Fede:
# ggpairs custom functions
corColor <- function(data, mapping, color = I("black"), sizeRange = c(1, 3), ...) {

  x   <- eval_data_col(data, mapping$x)
  y   <- eval_data_col(data, mapping$y)
  r   <- cor(x, y, "pairwise.complete.obs")
  rt  <- format(r, digits = 3)
  tt  <- as.character(rt)
  cex <- max(sizeRange)

  # helper function to calculate a useable size
  percent_of_range <- function(percent, range) {
    percent * diff(range) + min(range, na.rm = TRUE)
  }

  # plot correlation coefficient
  p <- ggally_text(label = tt, mapping = aes(), xP = 0.5, yP = 0.5,
                   size = I(percent_of_range(cex * abs(r), sizeRange)), color = color, ...) +
    theme(panel.grid.minor=element_blank(),
          panel.grid.major=element_blank())

  corColors <- RColorBrewer::brewer.pal(n = 7, name = "RdYlBu")[2:6]

  if (r <= boundaries[1]) {
    corCol <- corColors[1]
  } else if (r <= boundaries[2]) {
    corCol <- corColors[2]
  } else if (r < boundaries[3]) {
    corCol <- corColors[3]
  } else if (r < boundaries[4]) {
    corCol <- corColors[4]
  } else {
    corCol <- corColors[5]
  }

  p <- p +
    theme(panel.background = element_rect(fill = corCol))

  return(p)
}
```


```{r data import, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Import barcode counts per experiment
bc_files = list.files('/DATA/usr/m.trauernicht/projects/SuRE-TF/data/gcf5927_stimulation-1/results_e3_s1/',
                       full.names=T, patter='*_barcode_counts.tsv')
bc_list <- lapply(bc_files, fread, header = FALSE)
names(bc_list)<- gsub('.*//(.*?)_[CGAT]{8}.*_barcode_counts.tsv', 
                                    '\\1', 
                                    bc_files)

# Import barcode annotation
bc_annotation <- read.csv("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/library_design/output/mt20191218_tf-array.csv", header = T)
bc_annotation$TF <- as.character(bc_annotation$TF) 
bc_annotation$TF[bc_annotation$TF == "ctrl"] <- "hPGK"

barcodes <- bc_annotation$barcode
```

## Analysis


### Add barcode annotation to barcode counts & extract first bc read count information
```{r annotation, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
for (i in 1:length(bc_list)) {
  if (i == 1) {
  bc_df <- data.frame(bc_list[i])
  bc_df[3] <- names(bc_list[i])
  names(bc_df) <- c("barcode", "bc_counts", "condition")
  }
  else {
  bc_df_i <- data.frame(bc_list[i])
  bc_df_i[3] <- names(bc_list[i])
  names(bc_df_i) <- c("barcode", "bc_counts", "condition")
  bc_df <- rbind(bc_df, bc_df_i)
  }
}

# Match TF reporter to barcode
## Match barcode sequences from sequencing with barcodes from oligo design
bc_df <- merge(bc_df, bc_annotation, all = T)
bc_df$TF[bc_df$TF == "ctrl"] <- as_factor("hPGK")



## Make a graph to show total reads per condition
bc_df_new <- bc_df
bc_df_new_match <- bc_df_new[!is.na(bc_df_new$TF),]
bc_df_new_match$reads <- ave(bc_df_new_match$bc_counts, bc_df_new_match$condition, FUN = function(x) sum(x))
experimental_reads <- bc_df_new_match %>%
  dplyr::select("experiment" = condition, reads) %>%
  unique() %>%
  na.omit()


ggplot(data = experimental_reads, aes(y = reads, x = reorder(experiment, -reads))) + 
  geom_bar(stat = "identity") + xlab("Experimental condition") + ylab("Total read counts per experiment") +
  labs(title = "Total barcode reads per condition") + 
  theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1.0, vjust = 0))
```


### Get a closer look at unmatched barcodes 
```{r pie unmatch, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message = FALSE}
## Identify the unmapped fraction
bc_df_nomatch <- bc_df[is.na(bc_df$TF),]
bc_df_match <- bc_df[!is.na(bc_df$TF),]
bc_df_match$bc_counts <- as.numeric(bc_df_match$bc_counts)
bc_df_nomatch$bc_counts <- as.numeric(bc_df_nomatch$bc_counts)
bc_df_nomatch$bc_sum <- ave(bc_df_nomatch$bc_counts, bc_df_nomatch$barcode, FUN = function(x) sum(x))
bc_df_match$bc_sum <- ave(bc_df_match$bc_counts, bc_df_match$barcode, FUN = function(x) sum(x))
bc_df_nomatch <- bc_df_nomatch %>% dplyr::select(barcode, bc_sum) %>% unique()
bc_df_match <- bc_df_match %>% dplyr::select(barcode, bc_sum) %>% unique()
bc_df_nomatch$mean_coverage <- bc_df_nomatch$bc_sum / 22
bc_df_match$mean_coverage <- bc_df_match$bc_sum / 22

ggplot(data = bc_df_nomatch, aes(x = mean_coverage)) + 
  geom_density() + xlab("mean coverage") + 
  xlim(1,100) +
  labs(title = "barcode reads - unmatched barcodes") +
  theme_classic()

ggplot(data = bc_df_match, aes(x = mean_coverage)) + 
  geom_density() + xlab("mean coverage") + 
  xlim(1,100) +
  labs(title = "barcode reads - matched barcodes") +
  theme_classic()



## How many barcodes are unmatched?
n_match <- nrow(bc_df_match)
n_nomatch <- nrow(bc_df_nomatch)

# Create donut chart
data <- data.frame(
  lbls=c("matched:", "unmatched:"),
  count=c(n_match, n_nomatch)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "percentage of barcodes matched") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")




## How many reads are unmatched?
bc_df_match <- na.omit(bc_df_match)
n_match_reads <- sum(bc_df_match$bc_sum)
bc_df_nomatch$bc_sum[is.na(bc_df_nomatch$bc_sum)] <- 0
n_nomatch_reads <- sum(bc_df_nomatch$bc_sum)

# Create donut chart
data <- data.frame(
  lbls=c("matched:", "unmatched:"),
  count=c(n_match_reads, n_nomatch_reads)
)
 
# Compute percentages
data$fraction <- data$count / sum(data$count)
data$percentage <- data$fraction * 100


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)


# Compute the cumulative percentages (top of each rectangle)
data$ymax <- cumsum(data$fraction)

# Compute the bottom of each rectangle
data$ymin <- c(0, head(data$ymax, n=-1))

# Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

# Compute a good label
data$label <- paste0(data$lbls, "\n", round(data$percentage), "%")

# Make the plot
ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=lbls)) +
  geom_rect() +
  geom_text(x=2, aes(y=labelPosition, label=label, color=lbls), size=5) + # x here controls label position (inner / outer)
  scale_fill_manual(values = c("#1B998B", "#2D3047")) +
  scale_color_manual(values = c("#1B998B", "#2D3047")) +
  labs(title = "percentage of barcode reads matched") +
  coord_polar(theta="y") +
  xlim(c(0, 4)) +
  theme_void() +
  theme(legend.position = "none")
```

### Check if the pDNA-bc count correlates with the barcode count in the pDNA-insert-seq data
```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# pDNA_count <- bc_df %>% dplyr::select(barcode, pDNA_1, pDNA_2) %>%
#   mutate(pDNA = (pDNA_1 + pDNA_2) / 2) %>%
#   dplyr::select(barcode, pDNA) %>% 
#   mutate(pDNA = ave(pDNA, FUN = function(x) x/sum(x) *1000000))
# 
# 
# ref_seq <- ReadFasta("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/library_design/output/mt20191205_oligo_pool.fasta")
# ref_seq$sequence <- gsub("CATCGTCGCATCCAAGAG", "", ref_seq$sequence)
# ref_seq$barcode <- gsub(".*([A-Z]{12})$", "\\1", ref_seq$sequence)
# 
# # Add gc content info
# # Load reference file
# ref_seq_2 <- seqinr::read.fasta("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/library_design/output/mt20191205_oligo_pool.fasta")
# 
# # Compute gc contents
# gc <- compute_GC(ref_seq_2)
# gc <- gc %>% rownames_to_column(var = "name")
# ref_seq <- merge(gc, ref_seq, by = "name")
# 
# 
# pDNA_seq <- read_tsv("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/pDNA_insert_seq/pDNA-seq-starcode.tsv", col_names = c("sequence", "number"))
# 
# # Split up in insert and barcode part
# ## In my case, the barcode should be the last 12 bases of the sequence
# pDNA_seq$barcode <- gsub(".*([A-Z]{12})$", "\\1", pDNA_seq$sequence)
# pDNA_seq <- pDNA_seq %>% dplyr::select(barcode, number) %>%
#   unique()
# pDNA_seq <- pDNA_seq %>% 
#   group_by(barcode) %>% summarise(number = sum(number))
# 
# pDNA_count <- merge(pDNA_count, ref_seq)
# pDNA_count <- merge(pDNA_count, pDNA_seq)
# pDNA_count <- pDNA_count %>%
#   mutate(number = ave(number, FUN = function(x) x/sum(x) *1000000))
# pDNA_count$gc_status <- "high"
# pDNA_count$gc_status[pDNA_count$GC.content < 0.46] <- "low"
# 
# 
# 
# plot_ly(data = pDNA_count, x = ~pDNA, y = ~number, color = ~gc_status) %>% 
#   layout(xaxis = list(title = 'bc-seq bc rpm'),
#          yaxis = list(title = 'insert-seq bc rpm'))
# 
# ```


# ```{r barcode match, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message = FALSE}
# # Where could these unmatched, highly active barcodes come from?
# # Calculate levenshtein distance from barcodes in design to sequenced non-matched barcodes - ilter non-matched barcodes to only include active ones
# bc_nomatch <- bc_df_nomatch$barcode[bc_df_nomatch$bc_sum > 50]
# bc_match <- bc_annotation$barcode
# 
# # For each barcode in the deisgn, calculate the levenshtein distance to each non-matched barcode
# n <- 0
# for (i in 1:17580) {
#   if (i == 1) {
#     l <- data.frame(levenshtein.distance(bc_match[i], bc_nomatch))
#   }
#   else {
#     l[i] <- levenshtein.distance(bc_match[i], bc_nomatch)
# 
#     # Keep track of the progress
#     n <- n + length(i)
#     percent <- (n / 17580)*100
#     progress <- paste("progress:", percent, "%")
#     if (percent %% 10 == 0) {
#     print(progress)
#     }
#   }
# 
# }
# names(l) <- bc_match
# 
# # Only keep sequences with levenshtein distance of 1
# lev <- l
# lev <- lev[rowSums(lev == 1) == 1,colSums(lev == 1) >= 1]
# 
# 
# # Match barcodes with levenshtein distance of 1
# index <- data.frame(which(lev==1, arr.ind=TRUE))
# index <- tibble::rownames_to_column(index)
# for (i in 1:nrow(index)) {
#   index$colname[i] <- colnames(lev)[index$col[i]]
# }
# index <- index %>% dplyr::select(rowname, colname)
# names(index) <- c("non_match_barcode", "match_barcode")
# 
# 
# # Calculate correlation of each non-matched barcode to the two matched barcodes -> choose highest correlation bc
# # Correlation between matched and unmatched barcode counts
# match_bc_df <- bc_df[bc_df$barcode %in% index$match_barcode,c(1:23)]
# match_bc_df <- melt(match_bc_df, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
# names(match_bc_df) <- c("match_barcode", "condition", "match_counts")
# match_bc_df <- merge(match_bc_df, index, all = T)
# match_bc_df <- match_bc_df %>% dplyr::select(-non_match_barcode)
# 
# non_match_bc_df <- bc_df[bc_df$barcode %in% index$`non_match_barcode`,c(1:23)]
# setnames(non_match_bc_df, old = "barcode", new = "non_match_barcode")
# non_match_bc_df <- merge(non_match_bc_df, index, all = T)
# non_match_bc_df <- non_match_bc_df %>% group_by(match_barcode) %>% mutate(rep = seq_len( n() ) )
# non_match_bc_df <- melt(non_match_bc_df, id.vars = c("non_match_barcode", "rep", "match_barcode"), variable.name = "condition", value.name = "bc_counts")
# cor_bc_reads <- merge(match_bc_df, non_match_bc_df, all = T)
# cor_bc_reads[is.na(cor_bc_reads)] <- 0
# 
# # This method is not sensitive for data with very little counts - remove those
# cor_bc_reads$bc_counts <- as.numeric(cor_bc_reads$bc_counts)
# cor_bc_reads$match_counts <- as.numeric(cor_bc_reads$match_counts)
# cor_bc_reads$sum_counts <- ave(cor_bc_reads$bc_counts, cor_bc_reads$rep, cor_bc_reads$match_barcode,
#                                FUN = function(x) sum(x))
# cor_bc_reads <- cor_bc_reads[cor_bc_reads$sum_counts > 1000,]
# 
# cor_bc_reads$copies <- ave(cor_bc_reads$rep, cor_bc_reads$match_barcode,
#                                FUN = function(x) length(unique(x)))
# 
# cor_bc_reads <- unique(cor_bc_reads)
# 
# # For each barcode compute correlation of matched vs. unmatched rep 1-4
# n <- 0
# 
# for (i in unique(cor_bc_reads$non_match_barcode)) {
#     cor_bc_reads$cor[cor_bc_reads$non_match_barcode == i] <-
#       cor(cor_bc_reads$match_counts[cor_bc_reads$non_match_barcode == i],
#           cor_bc_reads$bc_counts[cor_bc_reads$non_match_barcode == i])
# 
#     n <- n + length(i)
#     percent <- (n / length(unique(cor_bc_reads$non_match_barcode)))*100
#     progress <- paste("progress:", percent, "%")
#     if (percent %% 10 == 0) {
#     print(progress)
#   }
# }
# 
# 
# # Filter out those with a weak correlation - this automatically keeps the correct ones with many counts
# cor_bc_reads[is.na(cor_bc_reads)] <- 0
# cor_bc_reads_low <- cor_bc_reads[cor_bc_reads$cor <= 0.75,]
# cor_bc_reads <- cor_bc_reads[cor_bc_reads$cor > 0.75,]
# cor_bc_reads <- cor_bc_reads %>% dplyr::select(-condition, -match_counts, -bc_counts)
# cor_bc_reads <- unique(cor_bc_reads)
# 
# 
# 
# # Correlation between matched and unmatched barcode counts
# index_3 <- cor_bc_reads
# match_bc_df <- bc_df[bc_df$barcode %in% index_3$match_barcode,c(1:23)]
# match_bc_df <- melt(match_bc_df, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
# names(match_bc_df) <- c("match_barcode", "condition", "match_counts")
# match_bc_df <- merge(match_bc_df, index_3, all = T)
# 
# non_match_bc_df <- bc_df[bc_df$barcode %in% index_3$non_match_barcode,c(1:23)]
# non_match_bc_df <- melt(non_match_bc_df, id.vars = c("barcode"), variable.name = "condition", value.name = "bc_counts")
# names(non_match_bc_df) <- c("non_match_barcode", "condition", "non_match_counts")
# non_match_bc_df <- merge(non_match_bc_df, index_3, all = T)
# non_match_bc_df <- non_match_bc_df %>% dplyr::select(-`non_match_barcode`)
# cor_bc_reads <- merge(match_bc_df, non_match_bc_df, all = T)
# cor_bc_reads[is.na(cor_bc_reads)] <- 0
# 
# sp <- ggscatter(cor_bc_reads, x = "match_counts", y = "non_match_counts",
#    add = "reg.line",
#    add.params = list(color = "blue", fill = "lightgray"), title = "correlation matched vs. unmatched barcodes",
#    conf.int = TRUE, ylab = "bc counts unmatched", xlab = "bc counts matched")
# sp + stat_cor(method = "pearson", label.x = 3, label.y = 6000) + geom_abline(linetype = "dashed")
# 
# 
# 
# cor_bc_reads <- cor_bc_reads %>% dplyr::select(match_barcode, non_match_barcode) %>% unique()
# 
# 
# # Change barcodes in bc_df to matched barcodes
# n <- 0
# 
# bc_nomatch_low <- bc_df_nomatch$barcode[bc_df_nomatch$bc_sum <= 100]
# bc_df <- subset(bc_df, !(bc_df$barcode %in% bc_nomatch_low))
# 
# for (i in unique(bc_df$barcode)) {
#   if (i %in% cor_bc_reads$non_match_barcode) {
#     k <- which(grepl(i, cor_bc_reads$non_match_barcode))
#     bc_df$barcode[bc_df$barcode == i] <- cor_bc_reads$match_barcode[k]
# 
#     n <- n + length(i)
#     percent <- (n / length(unique(bc_df$barcode))*100)
#     progress <- paste("progress:", percent, "%")
#     if (percent %% 10 == 0) {
#     print(progress)
#     }
#   }
# }
# 
# # Sum up identical barcodes
# bc_df[,2:23][is.na(bc_df[,2:23])] <- 0
# bc_df <- merge(bc_df, bc_annotation, by = "barcode", all = T)
# bc_df <- bc_df %>% dplyr::select(-TF.x, -Spacing.x, -Distance.x, -Barcode.x, -Promoter.x, -Background.x, -seq.x)
# setnames(bc_df,
#          old = c("TF.y", "Spacing.y", "Distance.y", "Barcode.y", "Promoter.y", "Background.y", "seq.y" ),
#          new = c("TF", "spacing", "distance", "bc-number", "promoter", "background", "seq"))
# bc_df$length <- nchar(bc_df$seq)
# 
# bc_df <- ddply(bc_df,~barcode + length + TF + spacing + distance + `bc-number` + promoter +
#                    background + seq,
#                  summarise, `2i_neg_LIF_r1` = sum(`2i_neg_LIF_r1`),
#             `2i_neg_LIF_r2` = sum(`2i_neg_LIF_r2`),
#             `2i_neg_LIF_r3` = sum(`2i_neg_LIF_r3`),
#             `2i_pos_LIF_r1` = sum(`2i_pos_LIF_r1`),
#             `2i_pos_LIF_r2` = sum(`2i_pos_LIF_r2`),
#             `2i_pos_LIF_r3` = sum(`2i_pos_LIF_r3`),
#             `LIF_pos_CH_r2` = sum(`LIF_pos_CH_r2`),
#             `LIF_pos_CH_r3` = sum(`LIF_pos_CH_r3`),
#             `LIF_pos_PD_r1` = sum(`LIF_pos_PD_r1`),
#             `LIF_pos_PD_r2` = sum(`LIF_pos_PD_r2`),
#             `LIF_pos_PD_r3` = sum(`LIF_pos_PD_r3`),
#             `N2B27_r1` = sum(`N2B27_r1`),
#             `N2B27_r2` = sum(`N2B27_r2`),
#             `N2B27_r3` = sum(`N2B27_r3`),
#             `NPC_r1` = sum(`NPC_r1`),
#             `NPC_r2` = sum(`NPC_r2`),
#             `NPC_r3` = sum(`NPC_r3`),
#             `pDNA_1` = sum(`pDNA_1`),
#             `pDNA_2` = sum(`pDNA_2`),
#             `vitA_r1` = sum(`vitA_r1`),
#             `vitA_r2` = sum(`vitA_r2`),
#             `vitA_r3` = sum(`vitA_r3`))
# 
# # As the levenshtein step needs a lot of time, I will run it once and then export and import it again
# filename <- SetFileName("_bc_df_levenshtein", "mt")
# setwd("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/results/")
# write.csv(bc_df, file = paste(filename,".csv", sep = ""), row.names = F)
```
**Conclusion barcode clustering:**  
- I manually added barcodes with high correlation and levenshtein distance of 1 to 1 barcode to get more reads



```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
## Import the previously saved read count data frame
bc_df <- read.csv("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/gcf5927_stimulation-1/results/mt20200504_bc_df_levenshtein.csv", header = T, stringsAsFactors = FALSE)
bc_df <- melt(bc_df, id.vars = c("barcode","TF", "spacing", "distance", "bc.number", 
                                 "promoter", "background", "seq", "length"), 
              variable.name = "condition", value.name = "bc_counts")
bc_df$bc_counts[is.na(bc_df$bc_counts)] <- 0

## Annotate controls
# Annotate the mutated motif of each TF
bc_df$neg_ctrls <- "No"
bc_df$neg_ctrls[grep("neg", bc_df$TF)] <- "Yes"

# Annotate hPGK postive control
bc_df$hPGK <- "No"
bc_df$hPGK[grep("hPGK", bc_df$TF)] <- "Yes"

# Annotate enhancer controls
bc_df$native_enhancer <- "No"
bc_df$native_enhancer[grep("klf2", bc_df$TF)] <- "Yes"

# Annotate random promoter control
bc_df$rand_promoter <- "No"
bc_df$rand_promoter[grep("Random", bc_df$promoter)] <- "Yes"

bc_df <- bc_df[!is.na(bc_df$condition),] 

# First compute reads per million to estimate the relative counts in their respective sample
for (i in unique(bc_df$condition)) {
  bc_df$rpm[bc_df$condition == i] <- (bc_df$bc_counts[bc_df$condition == i] + 1) / # Adds a pseudocount of 1
    sum(bc_df$bc_counts[bc_df$condition == i]) *1e6
}
```


## Compare differently clustered pDNA data

```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Make dataframe to compare raw counts between conditions
bc_df_filt <- bc_df[!is.na(bc_df$TF),]
bc_df_filt <- bc_df_filt[!is.na(bc_df_filt$condition),]
bc_df_cor <- bc_df_filt %>%
  dplyr::select(rpm, barcode, condition)

bc_df_cor <- bc_df_cor %>%
  mutate(rpm = as.integer(rpm)) %>%
  spread(condition, rpm) 

bc_df_cor[is.na(bc_df_cor)] <- 0



# Correlation matrix plot
n <- sample(1:nrow(bc_df_cor), 5000)
boundaries <- seq(from = 0.8, by = 0.05, length.out = 4)
plt <- ggpairs(bc_df_cor %>% dplyr::select(-barcode),
               upper = list(continuous = corColor),
               lower = list(continuous = function(data, mapping, ...) {
                   ggally_points(data = data[n, ], mapping = mapping, alpha = 0.1, size = 0.5) +
                   geom_abline(slope = 1, lty = "dashed", col = "red") +
                   theme_bw()}),
               diag = list(continuous = function(data, mapping, ...) {
                   ggally_densityDiag(data = data, mapping = mapping, alpha = 0.3, fill = "red") +
                   theme_bw()})) +
  ggtitle("Correlation Between All Samples") +
  # theme(text = element_text(size = 20)) +
  xlab("Counts") +
  ylab("Counts")

print(plt)





# Convert into data.frame with row.names for deseq2
bc_df_cor2 <- bc_df_cor %>%
  column_to_rownames("barcode")


#######################################
## Initialize deseq2

# Prepare metadata ready for deseq
metadata <- data.frame("sample_name" = names(bc_df_cor2)) %>%
  #filter(sample_name != "pDNA_1", sample_name != "pDNA_2") %>%
  mutate(condition = gsub("(.*)r[1-3]$", "\\1", sample_name),
         replicate = gsub(".*(r[1-3]$)", "\\1", sample_name))


# Initialize
rnaseq_dds <- DESeqDataSetFromMatrix(countData = bc_df_cor2,
                                     colData = metadata,
                                     design= ~ condition)

# Execute deseq2
rnaseq_dds <- DESeq(rnaseq_dds)


#######################################
## PCA analysis - quality control

# Get the "normalized" values and create PCA plot
# Note that "normalized" is simply log2 + 0.01 transformed normalized counts!
rnaseq_dds_norm <- normTransform(rnaseq_dds, pc = 0.01)
plt <- plotPCA(rnaseq_dds_norm, intgroup = c("condition"), ntop = 50)

plt + 
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_shape_manual()

## PCA plot alternative
rnaseq_dds_norm <- assay(vst(rnaseq_dds))
p <- pca(bc_df_cor2, metadata = metadata %>%
           column_to_rownames("sample_name"), removeVar = 0.1)
biplot(p, 
       colby = "condition", 
       shape = "replicate", 
       legendPosition = "right",
       legendLabSize = 8,
       legendTitleSize = 8,
       legendIconSize = 3, 
       lab = "")


## Correlation heatmap
bc_df_cor2$mean <- rowMeans(bc_df_cor2)
bc_df_cor2 <- bc_df_cor2 %>%
  filter(mean > 200) %>%
  dplyr::select(-mean)

cor_df <- cor(bc_df_cor2, method = "pearson")

pheatmap(cor_df, border_color = "black")
```

---


## Data quality plots
```{r read count 2, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message= FALSE}
# I want to show the following:
## 1: Read distribution of matched barcodes vs. unmatched barcode
ggplot(bc_df[bc_df$native_enhancer == "No" & bc_df$neg_ctrls == "No",], aes(x = TF, y = rpm)) +
  geom_bin2d(bins = 100) +
  theme_bw() +
  ylim(0,2500) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 1)) +
  facet_wrap(~condition)

bc_df_2 <- bc_df[bc_df$rpm <= 250,]
bc_df_2 <- bc_df_2[bc_df_2$rpm >= 0.5,]
bc_df_2 <- bc_df_2[!is.na(bc_df_2$TF),]

ggplot(bc_df_2, aes(x = rpm)) +
  geom_histogram(binwidth = 20) +
  theme_bw() +
  xlim(0,250)+
  ylim(0,6000)+
  facet_wrap(~condition)+
  theme(strip.background =element_rect(fill="#D6D5C9"))

ggplot(bc_df[bc_df$rpm >= 500 & !is.na(bc_df$TF),], aes(x = rpm)) +
  geom_histogram(binwidth = 20) +
  theme_bw() +
  xlim(250,1000)+
  ylim(0,50)+
  facet_wrap(~condition)+
  theme(strip.background =element_rect(fill="#D6D5C9"))

n_highly_expressed <- data.frame("condition" = unique(bc_df$condition),
                                 "n_bc" = "", stringsAsFactors = F)
for (i in unique(bc_df$condition)) {
  n_highly_expressed$n_bc[n_highly_expressed$condition == i] <- length(bc_df$barcode[bc_df$rpm > 500 & bc_df$condition == i])
}

plot_ly(n_highly_expressed, x = ~condition, y = ~as.numeric(n_bc), type = 'bar',
             marker = list(color = '#D6D5C9',
                           line = list(color = 'rgb(8,48,107)', width = 1.5))) %>% 
  layout(title = "Highly expressed barcodes",
         xaxis = list(title = "Number of barcodes with > 500 rpm"),
         yaxis = list(title = "Condition"))


## 2: How many barcodes can I find back at which cutoff? + What is the percentage of barcode reads that match the design at which cutoff?
## Identify the unmapped fraction
bc_fraction <- data.frame("condition" = unique(bc_df$condition),
                          "bcs_found" = "", stringsAsFactors = F)
rpm_cutoff <- data.frame("cutoff" = seq(0.0001,15,0.5))
bc_fraction <- merge(bc_fraction, rpm_cutoff)

for (i in unique(bc_fraction$cutoff)) {
  for (j in unique(bc_df$condition)) {
    bc_n <- bc_df[bc_df$rpm >= i & bc_df$condition == j,]
    bc_fraction$bcs_found[bc_fraction$cutoff == i & bc_fraction$condition == j] <- nrow(bc_n[!is.na(bc_n$TF),])/
      nrow(bc_annotation) *100
  }
}



## How many reads match to designed barcodes?
bc_reads <- data.frame("condition" = unique(bc_df$condition),
                          "bc_reads" = "", stringsAsFactors = F)
bc_reads <- merge(bc_reads, rpm_cutoff)

for (i in unique(bc_reads$cutoff)) {
  for (j in unique(bc_df$condition)) {
    bc_n <- bc_df[bc_df$rpm >= i & bc_df$condition == j,]
    bc_reads$bc_reads[bc_reads$cutoff == i & bc_reads$condition == j] <- sum(bc_n$rpm[!is.na(bc_n$TF)])/
      sum(bc_n$rpm) *100
  }
}

bc_fraction <- merge(bc_fraction, bc_reads)
bc_fraction$bcs_found <- as.numeric(bc_fraction$bcs_found)
bc_fraction$bc_reads <- as.numeric(bc_fraction$bc_reads)

#c("#1B998B", "#2D3047", "#FF9B71", "#ECDD7B")
# Plot to evaluate data quality per cutoff
ggplot(bc_fraction) +
  geom_point(aes(x = cutoff, y = bcs_found), color = '#1B998B', size = 1) +
  geom_line(aes(x = cutoff, y = bcs_found), color = '#1B998B', size = 1) +
  geom_point(aes(x = cutoff, y = bc_reads), color = 'black', size = 1) +
  geom_line(aes(x = cutoff, y = bc_reads), color = 'black', size = 1) +
  theme_bw()+
  xlab("rpm cutoff")+
  ylab("total barcodes (black) and matched barcode reads (green) detected (%)")+
  facet_wrap(~condition)+
  theme(strip.background =element_rect(fill="#D6D5C9"))

## 3: What is the correlation of the 24 cDNA bc counts with the pDNA bc counts? 
pDNA <- data.frame("pDNA" = bc_df$rpm[bc_df$condition == "pDNA_1"],
                   "barcode"= bc_df$barcode[bc_df$condition == "pDNA_1"], stringsAsFactors = F)
bc_df_2 <- merge(pDNA, bc_df, all = T)

ggplot(bc_df_2, aes(x = pDNA, y = rpm)) +
  geom_bin2d(bins = 100)+
  xlim(0,400) +
  ylim(0,400)+
  theme_bw()+
  facet_wrap(~condition)

cor <- data.frame("condition" = unique(bc_df_2$condition), "cor" = "", stringsAsFactors = F)

for (i in unique(bc_df_2$condition)) {
  x <- bc_df_2$rpm[bc_df_2$condition == i]
  y <- bc_df_2 %>% dplyr::select(barcode, pDNA) %>% unique()
  cor$cor[cor$condition == i] <- cor(x, y$pDNA)
}

bc_df <- merge(bc_df, cor, by = "condition", all = T)

## 4: Correlation plots of the replicates
## Combine replicates of normalized data in 3 different columns
bc_df$rep <- gsub(".*([1-3]{1}$)","\\1",bc_df$condition)
bc_df_rep <- bc_df[!is.na(bc_df$TF),] %>% dplyr::select(rep, rpm, barcode, condition) %>% unique()
bc_df_rep$condition <- gsub("(.*?)_r[1-3]$", "\\1", bc_df_rep$condition)
rep1 <- bc_df_rep[bc_df_rep$rep == 1,]
rep2 <- bc_df_rep[bc_df_rep$rep == 2,]
rep3 <- bc_df_rep[bc_df_rep$rep == 3,]
rep1 <- rep1 %>% dplyr::select(-rep)
rep2 <- rep2 %>% dplyr::select(-rep)
rep3 <- rep3 %>% dplyr::select(-rep)

names(rep1) <- c("rep1", "reporter", "condition")
names(rep2) <- c("rep2", "reporter", "condition")
names(rep3) <- c("rep3", "reporter", "condition")

bc_df_rep <- merge(rep1, rep2, all = TRUE)
bc_df_rep <- merge(bc_df_rep, rep3, all = TRUE)
bc_df_rep$neg_ctrl <- "No"
bc_df_rep$neg_ctrl[grep("random", bc_df_rep$reporter)] <- "Yes"

colors <- c("#2D3047", "#1B998B")

ggscatter(bc_df_rep, x = "rep1", y = "rep2",
   add = "reg.line",
   color = "neg_ctrl",
   size = 0.5,
   alpha = 0.2,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed") +
  xlim(0,10000) + ylim(0,10000) +
  scale_color_manual(values = colors)+facet_wrap(~condition)

ggscatter(bc_df_rep, x = "rep1", y = "rep3",
   add = "reg.line",
   color = "neg_ctrl",
   size = 0.5,
   alpha = 0.2,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep3",
   conf.int = TRUE, ylab = "rep3", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed")+
  xlim(0,10000) + ylim(0,10000) +
  scale_color_manual(values = colors)+facet_wrap(~condition)

ggscatter(bc_df_rep, x = "rep3", y = "rep2",
   add = "reg.line",
   color = "neg_ctrl",
   size = 0.5,
   alpha = 0.2,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep3 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep3") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed")+
  xlim(0,10000) + ylim(0,10000) +
  scale_color_manual(values = colors)+facet_wrap(~condition)


# Plot pDNA distribution vs. cutoff
pDNA_fraction <- bc_df[grep("pDNA", bc_df$condition),]
pDNA_fraction <- pDNA_fraction[!is.na(pDNA_fraction$TF),]
pDNA_fraction <- pDNA_fraction %>% dplyr::select(barcode, condition, rpm)
pDNA_fraction <- dcast(pDNA_fraction, barcode ~ condition)
pDNA_fraction <- pDNA_fraction %>% 
  mutate(pDNA = (pDNA_1 + pDNA_2) / 2) %>%
  dplyr::select(-pDNA_1, -pDNA_2)
pDNA_fr <- data.frame("cutoff" = seq(0,100, 1),
                      "bcs_missing" = "", stringsAsFactors=FALSE)
for (i in pDNA_fr$cutoff) {
  pDNA_fr$bcs_missing[pDNA_fr$cutoff == i] <- length(pDNA_fraction$barcode) -
    length(pDNA_fraction$barcode[pDNA_fraction$pDNA >= i])
}

ggplot(pDNA_fr) +
  geom_point(aes(x = cutoff, y = as.numeric(bcs_missing)), color = '#1B998B', size = 1) +
  geom_line(aes(x = cutoff, y = as.numeric(bcs_missing)), color = '#1B998B', size = 1) +
  theme_bw()+
  xlab("rpm cutoff")+
  ylab("barcodes excluded from analysis (18,000 in total)") +
  geom_vline(xintercept = 10, linetype = "dashed", color = "black")
```



```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Remove samples with low dynamic range
for (i in unique(bc_df$condition)) {
  bc_df$n_bc[bc_df$condition == i] <- length(bc_df$barcode[bc_df$rpm > 500 & bc_df$condition == i])
}
bc_df <- bc_df[bc_df$n_bc >= 20 | bc_df$condition == "pDNA_1" | bc_df$condition == "pDNA_2" ,] %>% dplyr::select(-n_bc)

# Remove samples with high pDNA contamination
bc_df <- bc_df[bc_df$cor <= 0.85 | bc_df$condition == "pDNA_1" | bc_df$condition == "pDNA_2",] %>% dplyr::select(-cor)

# Remove all non-matching reads
bc_df <- bc_df[!is.na(bc_df$TF),]
```




### Normalization of barcode counts:  
Divide cDNA barcode counts through pDNA barcode counts to get activity
```{r normalization, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# Add pDNA data as separate column
pDNA <- bc_df[grep("pDNA", bc_df$condition),] %>% dplyr::select(barcode, condition, rpm) %>% unique() %>%
  dcast(barcode ~ condition) %>%
  mutate(pDNA_counts_rpm = (pDNA_1 + pDNA_2) / 2) %>%
  dplyr::select(barcode, pDNA_counts_rpm)
bc_df <- merge(pDNA, bc_df)

# Compute activity by dividing cDNA bc counts through pDNA bc counts
bc_df$activity <- bc_df$rpm / bc_df$pDNA_counts_rpm

# Remove all activities that were computed with low pDNA bc counts, this keeps the noise level in the data low
bc_df$activity[bc_df$pDNA_counts_rpm <= 5] <- NA
```





### Calculate mean activity - filter out outlier barcodes 
```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE, message=FALSE}
# First identify and remove outlier barcodes - this removes the noise created by faulty barcode clustering etc. 
## Calculate mean and SD for each reporter
bc_df_cDNA <- bc_df[-grep("pDNA", bc_df$condition),]
bc_df_cDNA$reporter_id <- paste(bc_df_cDNA$TF, bc_df_cDNA$spacing, 
                                bc_df_cDNA$distance, bc_df_cDNA$promoter,
                                bc_df_cDNA$background, sep = "_")
bc_df_cDNA$mean_activity <- ave(bc_df_cDNA$activity, bc_df_cDNA$reporter_id, 
                                bc_df_cDNA$condition, FUN =
                                  function(x) mean(x))
bc_df_cDNA$sd_activity <- ave(bc_df_cDNA$activity, bc_df_cDNA$reporter_id, 
                              bc_df_cDNA$condition,  FUN =
                                  function(x) sd(x))

## Remove data points that are 2xSD away from the mean
bc_df_cDNA$upper_activity <- bc_df_cDNA$mean_activity + (2 * bc_df_cDNA$sd_activity)
bc_df_cDNA$lower_activity <- bc_df_cDNA$mean_activity - (2 * bc_df_cDNA$sd_activity)

bc_df_cDNA$low_outlier <- bc_df_cDNA$activity - bc_df_cDNA$lower_activity
bc_df_cDNA$high_outlier <- bc_df_cDNA$upper_activity - bc_df_cDNA$activity

## Plot effect of highest outlier bc -> SNP in minP promoter
outlier <- bc_df_cDNA[bc_df_cDNA$reporter_id == "Zfp42_5bp_21bp_minP_3",] %>% 
  dplyr::select(`bc.number`, activity) %>%
  unique()

ggplot(outlier, aes(x = `bc.number`, y = activity)) +
  geom_quasirandom() + theme_bw() +
  scale_x_continuous(breaks = seq(1, 8, by = 1)) +
  xlab("barcode #") + 
  labs(title = "Zfp42 reporter - TATA-box minP mutated", 
       subtitle = "bc8 AGAGGGTATATAAT -> AGAGGGGATATAAT" )


## Plot effect of highest outlier bc -> Elk1 outlier
outlier <- bc_df_cDNA[bc_df_cDNA$reporter_id == "Elk1_5bp_21bp_mCMV_2",] %>% 
  dplyr::select(`bc.number`, activity) %>%
  unique()

ggplot(outlier, aes(x = `bc.number`, y = activity)) +
  geom_quasirandom() + theme_bw() +
  scale_x_continuous(breaks = seq(1, 8, by = 1)) +
  xlab("barcode #") + 
  labs(title = "Elk1 reporter - bc1 attached to Pax6 reporter")



## Plot effect of highest outlier bc -> Elk1 outlier
outlier <- bc_df_cDNA[bc_df_cDNA$reporter_id == "Tcf7l2_5bp_10bp_hBGm_3",] %>% 
  dplyr::select(`bc.number`, activity) %>%
  unique()

ggplot(outlier, aes(x = `bc.number`, y = activity)) +
  geom_quasirandom() + theme_bw() +
  scale_x_continuous(breaks = seq(1, 8, by = 1)) +
  xlab("barcode #") + 
  labs(title = "Tcfl1 reporter - bc1 attached to multiple (less active) reporters")



## Choose arbitrary cutoff to get rid of most extreme outliers
bc_df_cDNA_filt <- bc_df_cDNA[bc_df_cDNA$low_outlier > -0.3 & bc_df_cDNA$high_outlier > -2,]

## Recalculate mean and sd
bc_df_cDNA_filt$mean_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, 
                                bc_df_cDNA_filt$condition, FUN =
                                  function(x) mean(x))
bc_df_cDNA_filt$sd_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, 
                              bc_df_cDNA_filt$condition,  FUN =
                                  function(x) sd(x))
```


```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# # Remove barcodes with multiple inserts attached
# bc_exclude <- read.csv("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/pDNA_seq/bc_exclude.csv") %>% dplyr::select(-X) %>% setnames("x", "barcode")
# exclude <- bc_df_cDNA_filt[!bc_df_cDNA_filt$barcode %in% bc_exclude$barcode,]
# 
# # Reassign barcodes with wrong inserts attached
# bc_replace <- read.csv("/DATA/usr/m.trauernicht/projects/tf_activity_reporter/data/SuRE_TF_1/pDNA_seq/bc_replace.csv") %>% dplyr::select(-X, -bc.match)
# change.df <- exclude[exclude$barcode %in% bc_replace$barcode,]
# exclude <- exclude[!exclude$barcode %in% bc_replace$barcode,]
# 
# change.df$bc.number <- 9
# change.df <- merge(change.df, bc_replace)
# e <- c("e11", "e93", "e97")
# change.df.e <- change.df[grep(paste(e, collapse = "|"), change.df$insert.match),]
# change.df <- change.df[-grep(paste(e, collapse = "|"), change.df$insert.match),]
# change.df <- change.df %>%
#   mutate(TF = gsub("(^.*?)_.*", "\\1", insert.match),
#          promoter = gsub(".*(minP|mCMV|hBGm|Random)_.*", "\\1", insert.match),
#          distance = gsub(".*_d-([0-9]{1,2}bp)_.*", "\\1", insert.match),
#          spacing = gsub(".*_s-([0-9]{1,2}bp)_.*", "\\1", insert.match),
#          background = gsub(".*([0-9]{1}$)", "\\1", insert.match),
#          reporter_id = paste(TF, spacing, distance, promoter, background, sep = "_"))
# change.df <- change.df %>% dplyr::select(-insert.match)
# 
# change.df.e <- change.df.e %>%
#   mutate(TF = gsub("(.*?)_(minP|mCMV|hBGm|Random)$", "\\1", insert.match),
#          promoter = gsub(".*(minP|mCMV|hBGm|Random)", "\\1", insert.match),
#          spacing = "",
#          distance = "",
#          background = "",
#          reporter_id = paste(TF, promoter, sep ="_"))
# change.df.e <- change.df.e %>% dplyr::select(-insert.match)
# 
# 
# exclude$reporter_id <- gsub("___", "_", exclude$reporter_id)
# exclude$reporter_id <- gsub("_0", "", exclude$reporter_id)
# 
# 
# 
# exclude <- rbind(exclude, change.df, change.df.e)
# 
# bc_df_cDNA_filt <- exclude
```


```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# Scale data to 1 for negative controls
bc_df_cDNA_filt_neg <- bc_df_cDNA_filt %>%
  dplyr::select(condition, activity, reporter_id, neg_ctrls, rand_promoter) %>%
  filter(neg_ctrls == "Yes", rand_promoter == "Yes") %>%
  unique() %>% 
  group_by(condition) %>%
  mutate(activity = mean(activity)) %>%
  ungroup() %>%
  dplyr::select(-reporter_id) %>%
  unique() %>%
  dplyr::select("background_activity" = activity, condition) %>%
  unique()



bc_df_cDNA_filt <- merge(bc_df_cDNA_filt, bc_df_cDNA_filt_neg, by = "condition")
bc_df_cDNA_filt <- bc_df_cDNA_filt %>%
  mutate(activity = activity / background_activity)

bc_df_cDNA_filt$mean_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, 
                                bc_df_cDNA_filt$condition, FUN =
                                  function(x) mean(x))
bc_df_cDNA_filt <- bc_df_cDNA_filt[!is.na(bc_df_cDNA_filt$condition),]
```



### Calculate correlations between technical replicates
```{r correlations_2, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
## Combine replicates in 8 different columns
bc_df_rep <- bc_df_cDNA_filt[bc_df_cDNA_filt$hPGK == "No" & bc_df_cDNA_filt$native_enhancer == "No" &
                          bc_df_cDNA_filt$rand_promoter == "No",] %>% 
  dplyr::select(`bc.number`, activity, condition, reporter_id) %>%
  spread(`bc.number`, activity)


# Correlation matrix plot
n <- sample(1:nrow(bc_df_rep), 5000)
boundaries <- seq(from = 0.75, by = 0.05, length.out = 4)
plt <- ggpairs(bc_df_rep %>% dplyr::select(-reporter_id, -condition),
               upper = list(continuous = corColor),
               lower = list(continuous = function(data, mapping, ...) {
                   ggally_points(data = data[n, ], mapping = mapping, alpha = 0.1, size = 0.5) +
                   geom_abline(slope = 1, lty = "dashed", col = "red") +
                   theme_bw()}),
               diag = list(continuous = function(data, mapping, ...) {
                   ggally_densityDiag(data = data, mapping = mapping, alpha = 0.3, fill = "red") +
                   theme_bw()})) +
  ggtitle("Correlation Between Technial Replicates") +
  theme(text = element_text(size = 20)) +
  xlab("Reporter activity") +
  ylab("Reporter activity") 

print(plt)
```



### Data quality plots - correlation between replicates
```{r correlations_3, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# Correlation plots of the replicates
## Combine replicates of normalized data in 3 different columns
bc_df_rep <- bc_df_cDNA_filt[bc_df_cDNA_filt$hPGK == "No" & bc_df_cDNA_filt$native_enhancer == "No" &
                          bc_df_cDNA_filt$rand_promoter == "No",] %>% 
  dplyr::select(rep, mean_activity, reporter_id, condition, neg_ctrls) %>% unique()
bc_df_rep$condition <- gsub("(.*?)_r[1-3]$", "\\1", bc_df_rep$condition)
bc_df_rep$rep <- paste("rep", bc_df_rep$rep, sep = "")
bc_df_rep <- bc_df_rep %>% 
  spread(rep, mean_activity)

colors <- c("#2D3047", "#1B998B")

ggscatter(bc_df_rep, x = "rep1", y = "rep2",
   add = "reg.line",
   color = "neg_ctrls",
   size = 0.5,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed") +
  xlim(0,50) + ylim(0,50) +
  scale_color_manual(values = colors) +
  facet_wrap(~condition)

ggscatter(bc_df_rep, x = "rep1", y = "rep3",
   add = "reg.line",
   color = "neg_ctrls",
   size = 0.5,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep1 vs rep3",
   conf.int = TRUE, ylab = "rep3", xlab = "rep1") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed")+
  xlim(0,50) + ylim(0,50) +
  scale_color_manual(values = colors)+
  facet_wrap(~condition)

ggscatter(bc_df_rep, x = "rep3", y = "rep2",
   add = "reg.line",
   color = "neg_ctrls",
   size = 0.5,
   add.params = list(color = "blue", fill = "lightgray"), title = "rep3 vs rep2",
   conf.int = TRUE, ylab = "rep2", xlab = "rep3") + 
  stat_cor(method = "pearson", label.x = 4, label.y = 0) + 
  geom_abline(linetype = "dashed")+
  xlim(0,50) + ylim(0,50) +
  scale_color_manual(values = colors)+
  facet_wrap(~condition)

# Based on this we can put some conditions on a blacklist
blacklist <- c("LIF_pos_CH_r3", "N2B27_r2", "NPC_r1", "LIF_pos_PD_r2", "LIF_pos_PD_r3", "vitA_r2", "X2i_neg_LIF_r1")
bc_df_cDNA_filt$blacklist <- "No"
bc_df_cDNA_filt$blacklist[bc_df_cDNA_filt$condition %in% blacklist] <- "Yes"
```


```{r out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# Mean of the three replicates
bc_df_cDNA_filt$condition <- gsub("(.*?)_r[1-3]$", "\\1", bc_df_cDNA_filt$condition)
bc_df_cDNA_filt$reporter_activity <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, bc_df_cDNA_filt$condition, FUN = function(x) mean(x))
bc_df_cDNA_filt$reporter_activity_sd <- ave(bc_df_cDNA_filt$activity, bc_df_cDNA_filt$reporter_id, bc_df_cDNA_filt$condition, FUN = function(x) sd(x))
```


```{r data export, out.width= "80%", fig.align= "center", echo=FALSE, warning= FALSE}
# Polish export dataframe
bc_df_cDNA_filt <- bc_df_cDNA_filt %>% 
  dplyr::select(-upper_activity, -lower_activity, 
         -high_outlier, -low_outlier,) %>% 
  setnames(old = c("mean_activity", "sd_activity"), 
           new = c("replicate_activity", "replicate_activity_sd")) %>% 
  mutate(log_activity = log2(activity),
         log_reporter_activity = log2(reporter_activity))
bc_df_cDNA_filt$condition <- gsub("^X", "", bc_df_cDNA_filt$condition)


# Export bc_df for cDNA analysis
filename <- SetFileName("_reporter_activity_filt", "mt")
setwd("/DATA/usr/m.trauernicht/projects/SuRE-TF/data/gcf5927_stimulation-1/results/")
write.csv(bc_df_cDNA_filt, file = paste(filename,".csv", sep = ""), row.names = F)
```

# Session Info
```{r}
paste("Run time: ",format(Sys.time()-StartTime))
getwd()
date()
sessionInfo()
```

